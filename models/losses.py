import torch
import torch.nn as nn
import torch.nn.functional as F
import math

# ==========================================
# 1. åŸºç¡€ç»„ä»¶ (é€‚é… 3D)
# ==========================================

def gaussian(window_size, sigma):
    # ç”Ÿæˆ 1D é«˜æ–¯åˆ†å¸ƒ
    gauss = torch.Tensor([math.exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])
    return gauss/gauss.sum()

class SSIMLoss3D(nn.Module):
    def __init__(self, window_size=11, size_average=True, channel=1):
        super(SSIMLoss3D, self).__init__()
        self.window_size = window_size
        self.size_average = size_average
        self.channel = channel
        
        # ğŸš€ [ä¼˜åŒ–] åˆå§‹åŒ–æ—¶åˆ›å»º Window å¹¶æ³¨å†Œä¸º Buffer
        # è¿™æ ·é¿å…äº†æ¯æ¬¡ Forward éƒ½åœ¨ CPU åˆ›å»º tensor å†ä¼ ç»™ GPU
        window = self.create_window(window_size, channel)
        self.register_buffer('window', window)

    def create_window(self, window_size, channel):
        _1D_window = gaussian(window_size, 1.5).unsqueeze(1)
        # ç”Ÿæˆ 2D é«˜æ–¯æ ¸ [1, 1, 11, 11]
        _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)
        
        # ğŸ”¥ å¿…é¡»æ‰©å±•ä¸º 4D: [C, 1, H, W] æ‰èƒ½è¢« F.conv2d æ¥å—
        window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()
        return window

    def _ssim_3d(self, img1, img2):
        # img: [B, C, T, H, W] -> reshape -> [B*T, C, H, W]
        b, c, t, h, w = img1.shape
        img1_2d = img1.reshape(-1, c, h, w)
        img2_2d = img2.reshape(-1, c, h, w)
        
        # è‡ªåŠ¨è·å– Buffer ä¸­çš„ window
        window = self.window
        if window.type_as(img1) != img1.type():
            window = window.type_as(img1)

        # ğŸ¨ [ä¼˜åŒ–] ä½¿ç”¨åå°„å¡«å…… (Reflection Padding) ä»£æ›¿é»˜è®¤è¡¥é›¶
        padding = self.window_size // 2
        
        def conv_valid(input, window):
            # å…ˆ pad å† convï¼Œå‡å°‘è¾¹ç•Œæ•ˆåº”
            padded = F.pad(input, (padding, padding, padding, padding), mode='reflect')
            return F.conv2d(padded, window, padding=0, groups=c)

        mu1 = conv_valid(img1_2d, window)
        mu2 = conv_valid(img2_2d, window)
        
        mu1_sq = mu1.pow(2)
        mu2_sq = mu2.pow(2)
        mu1_mu2 = mu1 * mu2
        
        sigma1_sq = conv_valid(img1_2d * img1_2d, window) - mu1_sq
        sigma2_sq = conv_valid(img2_2d * img2_2d, window) - mu2_sq
        sigma12 = conv_valid(img1_2d * img2_2d, window) - mu1_mu2
        
        C1 = 0.01**2
        C2 = 0.03**2
        
        ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2)) / \
                   ((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))
        
        if self.size_average:
            return ssim_map.mean()
        else:
            return ssim_map.mean(1).mean(1).mean(1)

    def forward(self, img1, img2):
        # é²æ£’æ€§å¤„ç†ï¼šNaN æ›¿æ¢
        if torch.isnan(img1).any() or torch.isnan(img2).any():
            img1 = torch.nan_to_num(img1, nan=0.0)
            img2 = torch.nan_to_num(img2, nan=0.0)
            
        return torch.clamp(1.0 - self._ssim_3d(img1, img2), min=0.0, max=1.0)


class TVLoss3D(nn.Module):
    def __init__(self, tv_loss_weight=1):
        super(TVLoss3D, self).__init__()
        self.tv_loss_weight = tv_loss_weight

    def forward(self, x):
        # x: [B, C, T, H, W]
        # ğŸ¨ [ä¼˜åŒ–] å‡çº§ä¸º L1 TV Loss (å„å‘å¼‚æ€§)ï¼Œæ›´å¥½åœ°ä¿ç•™å°–é”è¾¹ç¼˜
        h_tv = torch.abs(x[:, :, :, 1:, :] - x[:, :, :, :-1, :]).sum()
        w_tv = torch.abs(x[:, :, :, :, 1:] - x[:, :, :, :, :-1]).sum()
        
        count = x.numel()
        return self.tv_loss_weight * (h_tv + w_tv) / count


class AdaptiveCVLoss(nn.Module):
    """
    è‡ªé€‚åº”å˜å¼‚ç³»æ•°æŸå¤±
    ğŸš€ ä¼˜åŒ–ï¼šå®ç°äº† Batch ç»´åº¦ç‹¬ç«‹è®¡ç®—ï¼Œé˜²æ­¢ Batch å†…æ ·æœ¬ç›¸äº’å¹²æ‰°
    """
    def __init__(self, eps=1e-6, max_weight=10.0):
        super(AdaptiveCVLoss, self).__init__()
        self.eps = eps
        self.max_weight = max_weight 

    def forward(self, pred, target):
        pred = torch.nan_to_num(pred.float(), nan=0.0)
        target = torch.nan_to_num(target.float(), nan=0.0)

        # 1. åŸºç¡€ Loss (Charbonnier Loss: å¹³æ»‘ L1)
        diff = pred - target
        basic_loss = torch.sqrt(diff**2 + self.eps**2) # [B, C, T, H, W]

        # 2. è®¡ç®—åŠ¨æ€æƒé‡ (å‘é‡åŒ–ï¼Œæ—  CPU sync)
        with torch.no_grad():
            mask_nonzero = (target > self.eps).float()
            
            # ç»Ÿè®¡æ¯ä¸ªæ ·æœ¬çš„éé›¶åƒç´ ä¸ªæ•° [B, 1, 1, 1, 1]
            n_nonzero = mask_nonzero.sum(dim=(1, 2, 3, 4), keepdim=True)
            n_total = float(target.shape[1] * target.shape[2] * target.shape[3] * target.shape[4])
            
            # (A) å®è§‚æƒé‡
            ratio = n_total / (n_nonzero + 1.0)
            w_macro = torch.log1p(ratio)

            # (B) å¾®è§‚æƒé‡
            target_masked = target * mask_nonzero
            mean_val = target_masked.sum(dim=(1, 2, 3, 4), keepdim=True) / (n_nonzero + self.eps)
            
            var_val = (target_masked - mean_val)**2 * mask_nonzero
            std_val = torch.sqrt(var_val.sum(dim=(1, 2, 3, 4), keepdim=True) / (n_nonzero + self.eps))
            
            cv = std_val / (mean_val + self.eps)
            alpha = torch.clamp(cv, min=0.1, max=10.0)
            w_micro = 1.0 + alpha * torch.log1p(target)

            combined_weight = torch.clamp(w_macro * w_micro, max=self.max_weight)
            
            # åªæœ‰å½“éé›¶åƒç´ è¶³å¤Ÿå¤šæ—¶æ‰å¯ç”¨ CV æƒé‡
            valid_sample_mask = (n_nonzero > 10).float()
            final_weight_map = combined_weight * valid_sample_mask + 1.0 * (1.0 - valid_sample_mask)

        # 3. åŠ æƒ Loss
        weighted_loss = basic_loss * final_weight_map
        return weighted_loss.mean()


# ==========================================
# ğŸ›‘ [HybridLoss] é›†æˆç‰ˆ (Softmax æƒé‡)
# ==========================================
class HybridLoss(nn.Module):
    def __init__(self, consistency_scale=4):
        super(HybridLoss, self).__init__()
        # 1. åŸºç¡€æŸå¤±æ¨¡å—
        self.adaptive_loss = AdaptiveCVLoss() 
        self.ssim_loss = SSIMLoss3D()
        self.tv_loss = TVLoss3D(tv_loss_weight=1.0)
        
        # 2. ç‰©ç†ä¸€è‡´æ€§å‚æ•°
        self.scale = consistency_scale
        
        # 3. åŠ¨æ€æƒé‡ (å¯å­¦ä¹ çš„æƒé‡å‚æ•°)
        # ğŸ”¥ ä¿®æ”¹: æ”¹å› w_paramsï¼Œåˆå§‹ä¸º 0
        self.w_params = nn.Parameter(torch.zeros(4)) 

    def forward(self, pred, target, input_mosaic_low_res=None):
        """
        pred: [B, 1, T, 160, 160]
        target: [B, 1, T, 160, 160]
        input_mosaic_low_res: [B, 1, T, 160, 160]
        """
        
        # A. ç»†èŠ‚ä¸ç»“æ„æŸå¤±
        l_cv = self.adaptive_loss(pred, target)
        l_ssim = self.ssim_loss(pred, target)
        l_tv = self.tv_loss(pred)
        
        # B. ç‰©ç†ä¸€è‡´æ€§æŸå¤±
        target_reference = input_mosaic_low_res if input_mosaic_low_res is not None else target
        
        # ç‰©ç†é™é‡‡æ · (AvgPool)
        pred_down = F.avg_pool3d(pred, kernel_size=(1, self.scale, self.scale), stride=(1, self.scale, self.scale))
        ref_down = F.avg_pool3d(target_reference, kernel_size=(1, self.scale, self.scale), stride=(1, self.scale, self.scale))
        
        l_consist = F.l1_loss(pred_down, ref_down)
        
        # C. è‡ªåŠ¨åŠ æƒ (Softmax Weighted)
        # ğŸ”¥ ä¿®æ”¹: ä½¿ç”¨ Softmax ç¡®ä¿æƒé‡ä¸ºæ­£ä¸”å’Œä¸º1
        weights = torch.softmax(self.w_params, dim=0)
        
        # æ”¾å¤§æƒé‡ï¼Œè®©åˆå§‹å€¼æ¥è¿‘ 1.0 (å¦åˆ™åˆå§‹æ¢¯åº¦å¤ªå°)
        weights = weights * 4.0
        
        # åŠ æƒæ±‚å’Œ (æ¯ä¸€é¡¹éƒ½è‚¯å®šæ˜¯æ­£æ•°)
        loss = (weights[0] * l_cv + 
                weights[1] * l_ssim + 
                weights[2] * l_tv + 
                weights[3] * l_consist)
        
        return loss