import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math

# ==========================================
# 1. åŸºç¡€ç»„ä»¶ (SSIM è¾…åŠ©å‡½æ•° - ä¿æŒä¸å˜)
# ==========================================
def gaussian(window_size, sigma):
    gauss = torch.Tensor([math.exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])
    return gauss/gauss.sum()

def create_window(window_size, channel):
    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)
    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)
    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())
    return window

def _ssim(img1, img2, window, window_size, channel, size_average=True):
    mu1 = F.conv2d(img1, window, padding=window_size//2, groups=channel)
    mu2 = F.conv2d(img2, window, padding=window_size//2, groups=channel)
    mu1_sq = mu1.pow(2)
    mu2_sq = mu2.pow(2)
    mu1_mu2 = mu1 * mu2
    sigma1_sq = F.conv2d(img1*img1, window, padding=window_size//2, groups=channel) - mu1_sq
    sigma2_sq = F.conv2d(img2*img2, window, padding=window_size//2, groups=channel) - mu2_sq
    sigma12 = F.conv2d(img1*img2, window, padding=window_size//2, groups=channel) - mu1_mu2
    C1 = 0.01**2; C2 = 0.03**2
    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))
    if size_average: return ssim_map.mean()
    else: return ssim_map.mean(1).mean(1).mean(1)

# ==========================================
# 2. æ ¸å¿ƒæŸå¤±æ¨¡å—å®šä¹‰
# ==========================================

class TVLoss(nn.Module):
    """
    å…¨å˜åˆ†æŸå¤± (Total Variation Loss) - ä¿æŒä¸å˜
    ä½œç”¨ï¼šæ¶ˆé™¤ç½‘æ ¼ä¼ªå½±ï¼Œå¹³æ»‘å›¾åƒã€‚
    """
    def __init__(self, tv_loss_weight=1):
        super(TVLoss, self).__init__()
        self.tv_loss_weight = tv_loss_weight

    def forward(self, x):
        batch_size = x.size()[0]
        h_x = x.size()[2]
        w_x = x.size()[3]
        count_h = self._tensor_size(x[:, :, 1:, :])
        count_w = self._tensor_size(x[:, :, :, 1:])
        h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x - 1, :]), 2).sum()
        w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x - 1]), 2).sum()
        return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size

    def _tensor_size(self, t):
        return t.size()[1] * t.size()[2] * t.size()[3]

class AdaptiveCVLoss(nn.Module):
    """
    ğŸ”¥ [v1.8 æ ¸å¿ƒå‡çº§] è‡ªé€‚åº”å˜å¼‚ç³»æ•°å¹³è¡¡æŸå¤±
    
    å–ä»£äº†åŸæ¥çš„ BalancedCharbonnierLossã€‚
    æ–°ç‰¹æ€§ï¼š
    1. æ˜¾å¼ NaN æ¸…æ´—ï¼šä¿æŠ¤ 9060 XT ä¸è¢«è„æ•°æ®æå´©ã€‚
    2. è‡ªåŠ¨å®è§‚å¹³è¡¡ï¼šç”¨ log(Ratio) æ›¿ä»£æ­»æ¿çš„ 50/50ï¼Œé€‚åº” 33% ç¨€ç–åº¦ã€‚
    3. è‡ªåŠ¨å¾®è§‚å¹³è¡¡ï¼šåˆ©ç”¨ CV (å˜å¼‚ç³»æ•°) è‡ªåŠ¨è¯†åˆ«â€œè¶…çº§æ’æ”¾ç‚¹â€ï¼Œå¹¶ç”¨ Log å‡½æ•°åŠ æƒã€‚
    """
    def __init__(self, eps=1e-6, max_weight=50.0):
        super(AdaptiveCVLoss, self).__init__()
        self.eps = eps
        self.max_weight = max_weight 

    def forward(self, pred, target):
        # 1. å®‰å…¨æ¸…æ´— (Safety First) - å¼ºåˆ¶è½¬ float32 ç»Ÿè®¡
        pred = torch.nan_to_num(pred, nan=0.0)
        target = torch.nan_to_num(target, nan=0.0)

        # 2. å‡†å¤‡æ•°æ®
        target_flat = target.view(-1).float()
        mask_nonzero = target_flat > self.eps
        weight_map_flat = torch.ones_like(target_flat) # é»˜è®¤ä¸º 1.0 (èƒŒæ™¯)

        # 3. ç»Ÿè®¡æ•°é‡
        n_total = target_flat.numel()
        n_nonzero = mask_nonzero.sum()

        # å¦‚æœå…¨æ˜¯èƒŒæ™¯ï¼Œåªç®—åŸºç¡€è¯¯å·®
        if n_nonzero < 10:
            diff = pred - target
            loss = torch.sqrt(diff * diff + self.eps**2)
            return loss.mean()

        # 4. [å®è§‚] Step 1: 0 vs Non-0 å¹³è¡¡
        ratio = n_total / (n_nonzero + 1.0)
        w_macro = torch.log1p(ratio.detach())

        # 5. [å¾®è§‚] Step 2: åŸºäº CV çš„é«˜å€¼åŠ æƒ
        valid_values = target_flat[mask_nonzero]
        mu = valid_values.mean()
        std = valid_values.std()
        
        # è®¡ç®—å˜å¼‚ç³»æ•° CV
        cv = std / (mu + self.eps)
        alpha = torch.clamp(cv, min=0.1, max=10.0) # é™åˆ¶æ•æ„Ÿåº¦èŒƒå›´

        # è®¡ç®—å¾®è§‚æƒé‡
        w_micro = 1.0 + alpha * torch.log1p(valid_values)

        # 6. ç»„åˆæƒé‡ & æˆªæ–­
        combined_weight = w_macro * w_micro
        combined_weight = torch.clamp(combined_weight, max=self.max_weight)
        
        # å¡«å›æƒé‡å›¾
        weight_map_flat[mask_nonzero] = combined_weight
        weight_map = weight_map_flat.view_as(target)

        # 7. è®¡ç®—æœ€ç»ˆåŠ æƒ Loss
        diff = pred - target
        basic_loss = torch.sqrt(diff * diff + self.eps**2)
        
        # detach() æƒé‡ï¼Œåªä¼˜åŒ–é¢„æµ‹å€¼
        final_loss = (basic_loss * weight_map.detach()).mean()

        return final_loss

class SSIMLoss(torch.nn.Module):
    """
    ç»“æ„ç›¸ä¼¼æ€§æŸå¤± (SSIM) - ä¿æŒä¸å˜
    """
    def __init__(self, window_size=11, size_average=True):
        super(SSIMLoss, self).__init__()
        self.window_size = window_size
        self.size_average = size_average
        self.channel = 1
        self.window = create_window(window_size, self.channel)

    def forward(self, img1, img2):
        # æ˜¾å¼å¤„ç† NaNï¼Œé˜²æ­¢ SSIM è®¡ç®—å‡ºé”™
        img1 = torch.nan_to_num(img1, nan=0.0)
        img2 = torch.nan_to_num(img2, nan=0.0)

        # é€‚é… 5D è¾“å…¥
        if img1.dim() == 5:
            b, c, t, h, w = img1.size()
            img1 = img1.view(b * t, c, h, w)
            img2 = img2.view(b * t, c, h, w)

        (_, channel, _, _) = img1.size()
        if channel == self.channel and self.window.data.type() == img1.data.type():
            window = self.window
        else:
            window = create_window(self.window_size, channel)
            if img1.is_cuda: window = window.cuda(img1.get_device())
            window = window.type_as(img1)
            self.window = window
            self.channel = channel
            
        ssim_val = _ssim(img1, img2, window, self.window_size, channel, self.size_average)
        return F.relu(1 - ssim_val)

# ==========================================
# 3. è‡ªé€‚åº”æ··åˆæŸå¤± (Hybrid Wrapper)
# ==========================================
class HybridLoss(nn.Module):
    def __init__(self):
        super(HybridLoss, self).__init__()
        
        # ğŸ”¥ [ä¿®æ”¹ç‚¹] å°†æ—§çš„ BalancedCharbonnierLoss æ›¿æ¢ä¸º AdaptiveCVLoss
        self.pixel_loss = AdaptiveCVLoss(max_weight=50.0) 
        self.ssim_loss = SSIMLoss()
        self.tv_loss = TVLoss()
        
        # å¯å­¦ä¹ çš„æƒé‡å‚æ•° (åˆå§‹åŒ–ä¸º 0 -> æƒé‡ 1:1:1)
        self.w_params = nn.Parameter(torch.zeros(3))

        # Loss æ”¾å¤§å€æ•°ï¼Œä¿æŒ 100.0 ä¸å˜ï¼Œé˜²æ­¢æ•°å€¼ä¸‹æº¢
        self.loss_scale = 100.0

    def forward(self, pred, target, input_main=None):
        # 1. è®¡ç®—å„åˆ†é¡¹ Loss
        l_pix = self.pixel_loss(pred, target)
        l_ssim = self.ssim_loss(pred, target)
        
        # TV Loss ç»´åº¦é€‚é…
        if pred.dim() == 5:
            b, c, t, h, w = pred.size()
            l_tv = self.tv_loss(pred.view(b*t, c, h, w))
        else:
            l_tv = self.tv_loss(pred)
            
        # 2. æƒé‡è‡ªé€‚åº” (Softmax å½’ä¸€åŒ–)
        weights = torch.exp(self.w_params)
        weights = weights / weights.sum() * 3.0
        
        # 3. åŠ æƒæ±‚å’Œ
        total_loss = (weights[0] * l_pix + 
                      weights[1] * l_ssim + 
                      weights[2] * l_tv)
        
        return total_loss * self.loss_scale