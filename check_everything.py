import os
import torch
import torch.nn as nn
import time
import traceback

# ==========================================
# ğŸš€ 0. ç¯å¢ƒè¡¥ä¸ (é’ˆå¯¹ AMD ROCm)
# ==========================================
# 1. è®¾ç½®æŒä¹…åŒ–ç¼“å­˜ç›®å½• (åŠ é€Ÿå¯åŠ¨)
cache_dir = os.path.expanduser("~/.cache/miopen")
os.makedirs(cache_dir, exist_ok=True)
os.environ['MIOPEN_USER_DB_PATH'] = cache_dir
os.environ['MIOPEN_CUSTOM_CACHE_DIR'] = cache_dir

# 2. å¼ºåˆ¶ç”³è¯·æ˜¾å­˜ï¼Œé˜²æ­¢ MIOpen æŠ¥é”™
os.environ['MIOPEN_FORCE_USE_WORKSPACE'] = '1'
# 3. å±è”½è°ƒè¯•æ—¥å¿—
os.environ['MIOPEN_LOG_LEVEL'] = '4'
os.environ['MIOPEN_DEBUG_CONV_GEMM'] = '0' 
os.environ['MKL_THREADING_LAYER'] = 'GNU'

# å¯¼å…¥ä½ çš„æ¨¡å—
try:
    from models.network import DSTCarbonFormer
    from models.losses import HybridLoss
    print("âœ… æˆåŠŸå¯¼å…¥æ¨¡å‹å®šä¹‰æ–‡ä»¶")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿ä½ åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬: python check_system.py")
    exit()

def check_everything():
    print("\n========== ğŸ› ï¸ å…¨ç³»ç»Ÿè‡ªæ£€ç¨‹åºå¯åŠ¨ (120x120 å…¨åŠŸç‡ç‰ˆ) ==========")
    
    # 1. å‡†å¤‡ç¯å¢ƒ
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”¥ æ£€æµ‹è®¡ç®—è®¾å¤‡: {device}")
    if torch.cuda.is_available():
        print(f"   æ˜¾å¡å‹å·: {torch.cuda.get_device_name(0)}")
    
    # 2. æ¨¡æ‹Ÿå‡æ•°æ® (é€‚é… 120x120)
    # Batch=2 (æµ‹è¯•Batch), Time=3 (æ—¶é—´çª—å£), H=120, W=120 (æ–°å°ºå¯¸)
    print("\n[Step 1] ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ® (120x120, 9é€šé“)...")
    
    B, T, H, W = 2, 3, 120, 120  # ğŸ”¥ ä¿®æ”¹ç‚¹ï¼šå°ºå¯¸æ”¹ä¸º 120
    
    # è¾…åŠ©æµ: 9é€šé“ (7ç‰¹å¾ + 2åæ ‡)
    dummy_aux = torch.randn(B, 9, T, H, W).to(device)
    # ä¸»æµ: 1é€šé“
    dummy_main = torch.randn(B, 1, T, H, W).to(device)
    # æ ‡ç­¾: 1é€šé“
    dummy_target = torch.randn(B, 1, T, H, W).to(device)
    
    print(f"   Aux Shape: {dummy_aux.shape}")
    print(f"   Main Shape: {dummy_main.shape}")
    print("âœ… æ¨¡æ‹Ÿæ•°æ®å°±ç»ª")

    # 3. æµ‹è¯•æ¨¡å‹ (å« Mamba + MoE + FFTç¡¬çº¦æŸ)
    print("\n[Step 2] æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­...")
    # ğŸ”¥ ä¿®æ”¹ç‚¹ï¼šæµ‹è¯• Dim=64 çš„é«˜é…æ¨¡å¼
    test_dim = 64
    print(f"   âš™ï¸ æµ‹è¯•é…ç½®: Dim={test_dim}")
    
    try:
        model = DSTCarbonFormer(aux_c=9, main_c=1, dim=test_dim).to(device)
        
        # è®°å½•åˆå§‹æ˜¾å­˜
        if torch.cuda.is_available():
            mem_start = torch.cuda.memory_allocated()
            
        # è·‘ä¸€æ¬¡å‰å‘ä¼ æ’­
        start_time = time.time()
        pred = model(dummy_aux, dummy_main)
        end_time = time.time()
        
        # è®°å½•æ˜¾å­˜å˜åŒ–
        if torch.cuda.is_available():
            mem_used = (torch.cuda.memory_allocated() - mem_start) / 1024**2
            print(f"   å‰å‘æ˜¾å­˜å¢é‡: {mem_used:.2f} MB")
            
        print(f"   è¾“å‡ºå½¢çŠ¶: {pred.shape}")
        print(f"   è€—æ—¶: {(end_time - start_time)*1000:.2f} ms")
        
        if pred.shape == dummy_target.shape:
            print("âœ… æ¨¡å‹ç»“æ„æµ‹è¯•é€šè¿‡ï¼(120x120 å°ºå¯¸åŒ¹é…æˆåŠŸ)")
        else:
            print(f"âŒ å°ºå¯¸ä¸åŒ¹é…ï¼æœŸæœ› {dummy_target.shape}, å®é™… {pred.shape}")
            return
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹æŠ¥é”™: {e}")
        traceback.print_exc()
        return

    # 4. æµ‹è¯•æŸå¤±å‡½æ•° (å«ç‰©ç†ä¸€è‡´æ€§)
    print("\n[Step 3] æµ‹è¯• HybridLoss (å«ç‰©ç†å®ˆæ’æ£€æŸ¥)...")
    try:
        # åˆå§‹åŒ– Loss (scale=4 å¯¹åº” 120->30)
        criterion = HybridLoss(consistency_scale=4).to(device)
        
        # ğŸ”¥ å…³é”®ï¼šä¼ å…¥ input_mosaic_low_res (å³ dummy_main)
        loss = criterion(pred, dummy_target, input_mosaic_low_res=dummy_main)
        
        print(f"   è®¡ç®—å‡ºçš„ Loss å€¼: {loss.item()}")
        print(f"   åŠ¨æ€æƒé‡å‚æ•° requires_grad: {criterion.w_params.requires_grad}")
        
        if not torch.isnan(loss):
            print("âœ… æŸå¤±å‡½æ•°æµ‹è¯•é€šè¿‡ï¼")
        else:
            print("âŒ Loss å˜æˆäº† NaNï¼")
            return
            
    except Exception as e:
        print(f"âŒ æŸå¤±å‡½æ•°æŠ¥é”™: {e}")
        traceback.print_exc()
        return

    # 5. æµ‹è¯•åå‘ä¼ æ’­ (Mixed Precision)
    print("\n[Step 4] æµ‹è¯•åå‘ä¼ æ’­ (AMP æ··åˆç²¾åº¦)...")
    try:
        params = list(model.parameters()) + list(criterion.parameters())
        optimizer = torch.optim.AdamW(params, lr=0.001)
        scaler = torch.amp.GradScaler('cuda')
        
        optimizer.zero_grad()
        
        # æ¨¡æ‹Ÿä¸€æ¬¡å®Œæ•´çš„è®­ç»ƒæ­¥
        with torch.amp.autocast('cuda'):
            pred = model(dummy_aux, dummy_main)
            loss = criterion(pred, dummy_target, input_mosaic_low_res=dummy_main)
            
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        
        print("âœ… åå‘ä¼ æ’­æµ‹è¯•é€šè¿‡ï¼æ¢¯åº¦æ›´æ–°æ­£å¸¸ã€‚")
        
    except Exception as e:
        print(f"âŒ åå‘ä¼ æ’­æŠ¥é”™: {e}")
        traceback.print_exc()
        return

    print("\n========== ğŸ‰ æ­å–œï¼å…¨ç³»ç»Ÿè‡ªæ£€é€šè¿‡ï¼ ==========")
    print(f"ğŸ‘‰ ä½ çš„ 120x120 + Dim={test_dim} ç¯å¢ƒå·²å‡†å¤‡å°±ç»ªã€‚")
    print("ğŸ‘‰ å¯ä»¥è¿è¡Œ train.py å¼€å§‹æ­£å¼è®­ç»ƒäº†ï¼")

if __name__ == "__main__":
    check_everything()