import torch
from models.network import DSTCarbonFormer
from models.losses import HybridLoss
import time

def check_everything():
    print("\n========== ğŸ› ï¸ å…¨ç³»ç»Ÿè‡ªæ£€ç¨‹åºå¯åŠ¨ ==========")
    
    # 1. å‡†å¤‡ç¯å¢ƒ
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”¥ æ£€æµ‹è®¡ç®—è®¾å¤‡: {device}")
    
    # 2. æ¨¡æ‹Ÿå‡æ•°æ® (Batch=2, Time=3, H=128, W=128)
    print("\n[Step 1] ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®...")
    # è¾…åŠ©æµ: 9é€šé“
    dummy_aux = torch.randn(2, 9, 3, 128, 128).to(device)
    # ä¸»æµ: 1é€šé“
    dummy_main = torch.randn(2, 1, 3, 128, 128).to(device)
    # æ ‡ç­¾: 1é€šé“
    dummy_target = torch.randn(2, 1, 3, 128, 128).to(device)
    print("âœ… æ¨¡æ‹Ÿæ•°æ®å°±ç»ª")

    # 3. æµ‹è¯•æ¨¡å‹ (å« FFT ç¡¬çº¦æŸ)
    print("\n[Step 2] æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­ (å« FFT ç¡¬çº¦æŸ)...")
    try:
        model = DSTCarbonFormer(aux_c=9, main_c=1).to(device)
        
        # è®°å½•æ˜¾å­˜
        if torch.cuda.is_available():
            print(f"   æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated()/1024**2:.2f} MB")
            
        # è·‘ä¸€æ¬¡
        pred = model(dummy_aux, dummy_main)
        
        print(f"   è¾“å‡ºå½¢çŠ¶: {pred.shape}")
        if pred.shape == dummy_target.shape:
            print("âœ… æ¨¡å‹ç»“æ„æµ‹è¯•é€šè¿‡ï¼FFT ç¡¬çº¦æŸå±‚è¿è¡Œæ­£å¸¸ã€‚")
        else:
            print("âŒ å°ºå¯¸ä¸åŒ¹é…ï¼")
            return
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹æŠ¥é”™: {e}")
        import traceback
        traceback.print_exc()
        return

    # 4. æµ‹è¯•æŸå¤±å‡½æ•° (å«ç‰©ç†ä¸€è‡´æ€§)
    print("\n[Step 3] æµ‹è¯•æ··åˆæŸå¤±å‡½æ•° (å«ç‰©ç†å®ˆæ’ Loss)...")
    try:
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ•…æ„æŠŠ alpha, beta ç­‰è®¾ä¸º 1ï¼Œç¡®ä¿æ¯é¡¹éƒ½èƒ½ç®—å‡ºæ•°
        criterion = HybridLoss(alpha=1, beta=1, gamma=1, delta=1).to(device)
        
        # å…³é”®ç‚¹ï¼šä¸€å®šè¦ä¼ å…¥ input_main
        loss = criterion(pred, dummy_target, input_main=dummy_main)
        
        print(f"   è®¡ç®—å‡ºçš„ Loss å€¼: {loss.item()}")
        if not torch.isnan(loss):
            print("âœ… æŸå¤±å‡½æ•°æµ‹è¯•é€šè¿‡ï¼ç‰©ç†ä¸€è‡´æ€§ Loss è®¡ç®—æ­£å¸¸ã€‚")
        else:
            print("âŒ Loss å˜æˆäº† NaN (éæ•°å­—)ï¼å¯èƒ½æ¢¯åº¦çˆ†ç‚¸äº†ã€‚")
            return
            
    except Exception as e:
        print(f"âŒ æŸå¤±å‡½æ•°æŠ¥é”™: {e}")
        print("   ğŸ’¡ æç¤º: æ£€æŸ¥ä¸€ä¸‹æ˜¯å¦ä¼ å…¥äº† input_main å‚æ•°ï¼Ÿ")
        import traceback
        traceback.print_exc()
        return

    # 5. æµ‹è¯•åå‘ä¼ æ’­ (Mixed Precision)
    print("\n[Step 4] æµ‹è¯•åå‘ä¼ æ’­ (AMP æ··åˆç²¾åº¦)...")
    try:
        optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)
        scaler = torch.amp.GradScaler('cuda')
        
        optimizer.zero_grad()
        
        # æ¨¡æ‹Ÿä¸€æ¬¡å®Œæ•´çš„è®­ç»ƒæ­¥
        with torch.amp.autocast('cuda'):
            pred = model(dummy_aux, dummy_main)
            loss = criterion(pred, dummy_target, input_main=dummy_main)
            
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        
        print("âœ… åå‘ä¼ æ’­æµ‹è¯•é€šè¿‡ï¼æ¢¯åº¦æ›´æ–°æ­£å¸¸ã€‚")
        
    except Exception as e:
        print(f"âŒ åå‘ä¼ æ’­æŠ¥é”™: {e}")
        return

    print("\n========== ğŸ‰ æ­å–œï¼å…¨ç³»ç»Ÿè‡ªæ£€é€šè¿‡ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒï¼ ==========")

if __name__ == "__main__":
    check_everything()