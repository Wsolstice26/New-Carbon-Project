import numpy as np
import glob
import matplotlib.pyplot as plt
import os
import torch
import gc

def analyze_with_gpu():
    # -------------------------------------------------------
    # 1. è·¯å¾„ä¸è®¾å¤‡é…ç½®
    # -------------------------------------------------------
    data_path = "/home/wdc/Carbon-Emission-Super-Resolution/data/Train_Data_Yearly_Coords"
    files = glob.glob(os.path.join(data_path, "*.npy"))
    
    if not files:
        print(f"âŒ æœªåœ¨ {data_path} æ‰¾åˆ° .npy æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚")
        return

    # æ£€æŸ¥æ˜¯å¦æœ‰ GPU (ROCm/CUDA)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device} (AMD ROCm / NVIDIA CUDA)")

    # -------------------------------------------------------
    # 2. ç¬¬ä¸€é˜¶æ®µï¼šå¿«é€Ÿè®¡æ•° (Pre-scan)
    # -------------------------------------------------------
    print(f"ğŸ” [Phase 1] æ­£åœ¨é¢„æ‰«æ {len(files)} ä»½æ–‡ä»¶ä»¥è®¡ç®—å†…å­˜éœ€æ±‚...")
    
    total_valid_pixels = 0
    total_pixels_count = 0
    zero_count_global = 0

    for i, f in enumerate(files):
        # åªæ˜¯è¯»å–å½¢çŠ¶å’Œç®€å•çš„ç»Ÿè®¡ï¼Œä¸éœ€è¦å…¨éƒ¨åŠ è½½è¿›æ˜¾å­˜ï¼Œæˆ–è€…åˆ†å—å¤„ç†
        # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œè¿˜æ˜¯åŠ è½½ numpyï¼Œè½¬ tensor å¤„ç†ä¼šå¾ˆå¿«
        try:
            # å³ä½¿æ˜¯ Numpy Load ä¹Ÿå¯èƒ½ç”± CPU ç“¶é¢ˆï¼Œä½†è¿™é‡Œå¾ˆéš¾ä¼˜åŒ– IOï¼Œä¸»è¦ä¼˜åŒ–è®¡ç®—
            raw_data = np.load(f)
            total_pixels_count += raw_data.size
            
            # è½¬ä¸º Tensor æ‰”è¿› GPU
            # ä½¿ç”¨ float32 èŠ‚çœæ˜¾å­˜
            tensor_data = torch.from_numpy(raw_data).to(device, dtype=torch.float32)
            
            # GPU æé€Ÿå¤„ç† NaN
            tensor_data = torch.nan_to_num(tensor_data, nan=0.0)
            
            # GPU é€»è¾‘ç­›é€‰
            mask = tensor_data > 1e-6
            valid_count = mask.sum().item() # è·å–æ•°é‡
            
            total_valid_pixels += valid_count
            zero_count_global += (raw_data.size - valid_count)
            
            # é‡Šæ”¾æ˜¾å­˜
            del tensor_data, mask, raw_data
            
            # æ‰“å°è¿›åº¦
            print(f"\r  Scanned {i+1}/{len(files)} | Found {total_valid_pixels} valid pixels", end="")
            
        except Exception as e:
            print(f"\nâš ï¸ è¯»å–æ–‡ä»¶ {f} å‡ºé”™: {e}")

    print(f"\nâœ… é¢„æ‰«æå®Œæˆã€‚éœ€è¦å­˜å‚¨ {total_valid_pixels} ä¸ªæµ®ç‚¹æ•°ã€‚")
    
    # -------------------------------------------------------
    # 3. å†…å­˜åˆ†é… (Allocation)
    # -------------------------------------------------------
    # float32 æ¯ä¸ªå  4 å­—èŠ‚ã€‚7.6äº¿ * 4 â‰ˆ 2.8 GBã€‚è¿™å®Œå…¨å¯ä»¥å¡è¿›å†…å­˜ã€‚
    # ä¹‹å‰æŠ¥é”™æ˜¯å› ä¸º Python List çš„é¢å¤–å¼€é”€ã€‚
    try:
        big_array = np.zeros(total_valid_pixels, dtype=np.float32)
        print(f"ğŸ’¾ å·²åˆ†é…ä¸»æœºå†…å­˜: {big_array.nbytes / 1024**3:.2f} GB")
    except MemoryError:
        print("âŒ å†…å­˜ä¸è¶³ï¼æ— æ³•ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰éé›¶æ•°æ®ã€‚è¯·è€ƒè™‘ä½¿ç”¨æµå¼ç»Ÿè®¡ç®—æ³•ã€‚")
        return

    # -------------------------------------------------------
    # 4. ç¬¬äºŒé˜¶æ®µï¼šGPU å¡«å…… (Fill)
    # -------------------------------------------------------
    print(f"ğŸ“¥ [Phase 2] æ­£åœ¨åˆ©ç”¨ GPU æ‰¹é‡æ¸…æ´—å¹¶å¡«å…¥æ•°æ®...")
    
    current_idx = 0
    
    for i, f in enumerate(files):
        raw_data = np.load(f)
        
        # CPU -> GPU
        tensor_data = torch.from_numpy(raw_data).to(device, dtype=torch.float32)
        
        # GPU è®¡ç®—
        tensor_data = torch.nan_to_num(tensor_data, nan=0.0)
        valid_pixels = tensor_data[tensor_data > 1e-6] # Boolean Masking
        
        # GPU -> CPU (åªä¼ å›æœ‰æ•ˆæ•°æ®)
        # è¿™ä¸€æ­¥å°†æ¸…æ´—å¥½çš„æ•°æ®å—æ‹‰å› CPU
        valid_chunk = valid_pixels.cpu().numpy()
        
        # å¡«å…¥å¤§æ•°ç»„
        chunk_len = len(valid_chunk)
        big_array[current_idx : current_idx + chunk_len] = valid_chunk
        current_idx += chunk_len
        
        # æ¸…ç†æ˜¾å­˜
        del tensor_data, valid_pixels, valid_chunk, raw_data
        # torch.cuda.empty_cache() # AMD ROCm ä¸Šé¢‘ç¹è°ƒç”¨å¯èƒ½ä¼šæ…¢ï¼Œä¸€èˆ¬ä¸éœ€è¦
        
        if i % 5 == 0:
             print(f"\r  Processed {i+1}/{len(files)} | Filled: {current_idx/total_valid_pixels*100:.1f}%", end="")

    print("\nâœ… æ•°æ®è£…è½½å®Œæˆã€‚å¼€å§‹ç»Ÿè®¡...")

    # -------------------------------------------------------
    # 5. ç»Ÿè®¡åˆ†æ (Statistics)
    # -------------------------------------------------------
    sparsity = (zero_count_global / total_pixels_count) * 100
    
    print("\n===== ğŸŒ ç¢³æ’æ”¾æ•°æ®å…¨é‡ä½“æ£€æŠ¥å‘Š =====")
    print(f"æ€»åƒç´ æ•°: {total_pixels_count}")
    print(f"ç¨€ç–åº¦ (é›¶å€¼å æ¯”): {sparsity:.2f}%")
    print(f"æœ‰å€¼åƒç´ æ•°: {len(big_array)}")
    
    if len(big_array) > 0:
        # è®¡ç®—åˆ†ä½æ•° (NumPy åœ¨ CPU ä¸Šç®—è¿™ä¸ªå¾ˆå¿«)
        quantiles = [0.25, 0.5, 0.75, 0.9, 0.95, 0.99]
        print("â³ æ­£åœ¨è®¡ç®—åˆ†ä½æ•°...")
        values = np.quantile(big_array, quantiles)
        
        print("-" * 35)
        print("ğŸ“Š éé›¶åƒç´ æ•°å€¼åˆ†å¸ƒ (å¨/åƒç´ ):")
        for q, v in zip(quantiles, values):
            print(f"  {int(q*100):2d}% çš„åƒç´ å€¼ä½äº: {v:.6f}")
        
        print("-" * 35)
        print(f"æœ€å¤§å€¼: {np.max(big_array):.6f}")
        print(f"å¹³å‡å€¼: {np.mean(big_array):.6f}")
        print(f"æ ‡å‡†å·®: {np.std(big_array):.6f}")
    
        # ç»˜å›¾
        print("ğŸ¨ æ­£åœ¨ç»˜åˆ¶ç›´æ–¹å›¾...")
        plt.figure(figsize=(10, 6))
        # è¿™é‡Œçš„ bins å¯ä»¥è®¾å¤§ä¸€ç‚¹ï¼Œå› ä¸ºæ•°æ®é‡å¤§
        plt.hist(big_array, bins=200, color='salmon', edgecolor='black', log=True)
        plt.title("Frequency Distribution of Carbon Emissions (Non-zero, Log-Scale Y)")
        plt.xlabel("Emission Value (Tons)")
        plt.ylabel("Frequency (Log Scale)")
        plt.grid(axis='y', alpha=0.3)
        plt.savefig("distribution_full_gpu.png")
        print("\nğŸ“ˆ åˆ†å¸ƒç›´æ–¹å›¾å·²ä¿å­˜è‡³: distribution_full_gpu.png")
    else:
        print("âš ï¸ æœªå‘ç°éé›¶åƒç´ æ•°æ®ã€‚")

if __name__ == "__main__":
    analyze_with_gpu()