import os
import gc  # å¼•å…¥åƒåœ¾å›æ”¶æ¨¡å—

# ==========================================
# ğŸš€ [ç¯å¢ƒè¡¥ä¸] ä¿®æ­£ç‰ˆ
# ==========================================

# 1. MIOpen ç¼“å­˜ (ä¿ç•™ï¼è¿™æ˜¯å¥½ä¸œè¥¿ï¼ŒåŠ é€Ÿå¯åŠ¨)
cache_dir = os.path.expanduser("~/.cache/miopen")
os.makedirs(cache_dir, exist_ok=True)
os.environ['MIOPEN_USER_DB_PATH'] = cache_dir
os.environ['MIOPEN_CUSTOM_CACHE_DIR'] = cache_dir

# 2. å¼ºåˆ¶å¼€å¯ Workspace (ä¿ç•™ï¼Œé˜²æ­¢æŠ¥é”™ï¼Œä½†è¦æ³¨æ„å®ƒä¼šåƒæ˜¾å­˜)
os.environ['MIOPEN_FORCE_USE_WORKSPACE'] = '1'

# 3. æ—¥å¿—ä¼˜åŒ– (ä¿ç•™)
os.environ['MIOPEN_LOG_LEVEL'] = '4'
os.environ['MIOPEN_DEBUG_CONV_GEMM'] = '0'
os.environ['MKL_THREADING_LAYER'] = 'GNU'
os.environ['MKL_SERVICE_FORCE_INTEL'] = '1'

# âŒ [åˆ é™¤/æ³¨é‡Š] æ˜¾å­˜é”ï¼
# è¿™è¡Œä»£ç åœ¨æé™æ˜¾å­˜ä¸‹ä¼šå¯¼è‡´åˆ†é…å¤±è´¥ï¼Œè®© PyTorch è‡ªåŠ¨ç®¡ç†å§
# os.environ['PYTORCH_ALLOC_CONF'] = 'max_split_size_mb:128'

import torch
import torch.nn as nn
import time
import numpy as np

# å¼€å¯æ€§èƒ½æ¨¡å¼
torch.backends.cudnn.benchmark = True  
torch.backends.cudnn.deterministic = False

# ==========================================
# å¯¼å…¥é¡¹ç›®æ¨¡å—
# ==========================================
try:
    from models.blocks import (
        MultiScaleBlock3D, SFTLayer3D, MoEBlock
    )
    from models.network import DSTCarbonFormer 
    from mamba_ssm import Mamba
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    exit()

# ... MambaAdapter ä¿æŒä¸å˜ ...
class MambaAdapter(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.mamba = Mamba(d_model=dim, d_state=16, d_conv=4, expand=2)
    def forward(self, x):
        B, C, T, H, W = x.shape
        x_flat = x.flatten(2).transpose(1, 2)
        out = self.mamba(x_flat)
        return out.transpose(1, 2).view(B, C, T, H, W)

# ==========================================
# âš¡ï¸ æ”¹è¿›çš„æµ‹è¯•å‡½æ•° (å¢åŠ æ˜¾å­˜æ¸…ç†)
# ==========================================
def benchmark(name, module, inputs, iters=50):
    print(f"--------------------------------------------------")
    print(f"ğŸ§ª æµ‹è¯•æ¨¡å—: {name}")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    try:
        module = module.to(device)
        module.eval()
        
        # ç¡®ä¿è¾“å…¥åœ¨ GPU
        if isinstance(inputs, (tuple, list)):
            inputs = [x.to(device) for x in inputs]
        else:
            inputs = [inputs.to(device)]
            
        # 1. é¢„çƒ­
        print("   ğŸ”¥ é¢„çƒ­ä¸­...")
        with torch.no_grad():
            for _ in range(5): # å‡å°‘é¢„çƒ­æ¬¡æ•°ï¼Œçœç‚¹æ—¶é—´
                _ = module(*inputs)
        torch.cuda.synchronize()
        
        # 2. è®¡æ—¶
        start = time.time()
        with torch.no_grad():
            for _ in range(iters):
                _ = module(*inputs)
        torch.cuda.synchronize()
        
        avg_time = (time.time() - start) / iters * 1000 
        print(f"   â±ï¸ å¹³å‡è€—æ—¶: {avg_time:.2f} ms / batch")
        return avg_time

    except Exception as e:
        print(f"   âŒ æµ‹è¯•å¤±è´¥ (OOM): {e}")
        return float('inf')
    
    finally:
        # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šæ¯æ¬¡æµ‹å®Œï¼Œå¼ºåˆ¶æ‰“æ‰«æˆ˜åœºï¼ğŸ”¥ğŸ”¥ğŸ”¥
        del module
        del inputs
        gc.collect()           # Python åƒåœ¾å›æ”¶
        torch.cuda.empty_cache() # PyTorch æ˜¾å­˜é‡Šæ”¾
        print("   ğŸ§¹ æ˜¾å­˜å·²æ¸…ç†")

if __name__ == "__main__":
    if torch.cuda.is_available():
        print(f"ğŸ”¥ ç¡¬ä»¶: {torch.cuda.get_device_name(0)}")
        # æ‰“å°å½“å‰æ˜¾å­˜ä½¿ç”¨æƒ…å†µ
        print(f"ğŸ“¦ åˆå§‹æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated()/1024**3:.2f} GB")

    # ==========================================
    # âš ï¸ å»ºè®®å‚æ•°
    # Batch=16 åœ¨ 120x120 ä¸‹çœŸçš„å¤ªæé™äº†
    # å¦‚æœè¿™æ¬¡è¿˜çˆ†ï¼Œè¯·åŠ¡å¿…æ”¹å› 12
    # ==========================================
    B, T, H, W = 16, 3, 120, 120  
    DIM = 32 
    
    print(f"âš™ï¸ æµ‹è¯•å‚æ•°: Batch={B}, Dim={DIM}, Size={H}x{W}")
    
    # æ„é€ æ•°æ®
    df = torch.randn(B, DIM, T, H, W)
    da = torch.randn(B, DIM, T, H, W) 
    dra = torch.randn(B, 9, T, H, W)
    dm = torch.randn(B, 1, T, H, W)
    
    results = {}

    try:
        results['3D Conv'] = benchmark("3Då·ç§¯", MultiScaleBlock3D(channels=DIM), df)
        results['MoE'] = benchmark("MoE", MoEBlock(dim=DIM, num_experts=3, top_k=1), df)
        results['Mamba'] = benchmark("Mamba", MambaAdapter(dim=DIM), df)
        results['Fusion'] = benchmark("èåˆå±‚", SFTLayer3D(channels=DIM), (df, da))
        
        # å…¨æ¨¡å‹æœ€åæµ‹
        full_model = DSTCarbonFormer(aux_c=9, main_c=1, dim=DIM)
        results['FULL MODEL'] = benchmark("DSTCarbonFormer", full_model, (dra, dm))

        print("\nğŸ“Š ç»“æœæ±‡æ€»:")
        for k, v in results.items():
            print(f"{k}: {v:.2f} ms")
            
    except Exception as e:
        print(f"\nâŒ ä¸¥é‡é”™è¯¯: {e}")