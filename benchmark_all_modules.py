import os
import torch
import torch.nn as nn
import time
import numpy as np

# ==========================================
# ğŸš€ ç¯å¢ƒè¡¥ä¸ (é’ˆå¯¹ 14600K + 9060 XT)
# ==========================================

# 1. è§£å†³ MIOpen Workspace æŠ¥é”™ï¼Œå¼ºåˆ¶ç”³è¯·æ˜¾å­˜ç©ºé—´ä»¥æ¢å– 3D å·ç§¯é€Ÿåº¦
os.environ['MIOPEN_FORCE_USE_WORKSPACE'] = '1'
# å…è®¸ MIOpen åŠ¨æ€æœç´¢æœ€ä½³ç®—æ³•ï¼ˆé…åˆ benchmark=Trueï¼‰
os.environ['MIOPEN_DEBUG_CONV_GEMM'] = '0' 

# 2. è§£å†³ Intel CPU åœ¨å®¹å™¨å†…å¯èƒ½å¼•å‘çš„æ•°å­¦åº“å†²çª
os.environ['MKL_THREADING_LAYER'] = 'GNU'
os.environ['MKL_SERVICE_FORCE_INTEL'] = '1'

# 3. å¼€å¯æé™æ€§èƒ½æ¨¡å¼
torch.backends.cudnn.benchmark = True  
torch.backends.cudnn.deterministic = False

# ==========================================
# å¯¼å…¥é¡¹ç›®æ¨¡å—
# ==========================================
try:
    from models.blocks import (
        MultiScaleBlock3D, SFTLayer3D, EfficientContextBlock, 
        MoEBlock
        # SimpleMambaBlock  <-- å·²ç§»é™¤æ—§ç‰ˆ
    )
    from models.losses import HybridLoss
    from models.network import DSTCarbonFormer 
    
    # âœ… å¯¼å…¥å®˜æ–¹ Mamba
    from mamba_ssm import Mamba
    
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}ã€‚è¯·ç¡®è®¤ä½ åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬ã€‚")
    exit()

# ==========================================
# ğŸ› ï¸ Mamba å½¢çŠ¶é€‚é…å™¨ (ç”¨äºå•ç‹¬æµ‹è¯•æ¨¡å—)
# ==========================================
class MambaAdapter(nn.Module):
    """
    å®˜æ–¹ Mamba éœ€è¦ (B, L, D) è¾“å…¥ï¼Œè€Œæˆ‘ä»¬çš„æ•°æ®æ˜¯ (B, C, T, H, W)ã€‚
    è¿™ä¸ªç±»ä¸“é—¨ç”¨äº benchmark å•ç‹¬çš„ Mamba æ¨¡å—ï¼Œè´Ÿè´£å½¢çŠ¶è½¬æ¢ã€‚
    """
    def __init__(self, dim):
        super().__init__()
        # ä½¿ç”¨å®˜æ–¹ Mamba åˆå§‹åŒ–
        self.mamba = Mamba(
            d_model=dim, 
            d_state=16, 
            d_conv=4, 
            expand=2
        )

    def forward(self, x):
        # x: (B, C, T, H, W)
        B, C, T, H, W = x.shape
        # å±•å¹³: (B, C, L) -> (B, L, C)
        x_flat = x.flatten(2).transpose(1, 2)
        # è¿›å®˜æ–¹ Mamba
        out = self.mamba(x_flat)
        # è¿˜åŸ: (B, L, C) -> (B, C, T, H, W)
        return out.transpose(1, 2).view(B, C, T, H, W)

# ==========================================
# æµ‹è¯•å‡½æ•°
# ==========================================
def benchmark(name, module, inputs, iters=50):
    print(f"--------------------------------------------------")
    print(f"ğŸ§ª æµ‹è¯•æ¨¡å—: {name}")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    try:
        module = module.to(device)
        module.eval()
        
        if isinstance(inputs, (tuple, list)):
            inputs = [x.to(device) for x in inputs]
        else:
            inputs = [inputs.to(device)]
            
        # 1. é¢„çƒ­ (å¯»æ‰¾æœ€ä½³ç®—æ³•)
        print("   ğŸ”¥ é¢„çƒ­ä¸­ (AMD æ˜¾å¡æ­£åœ¨åŒ¹é…æœ€ä½³ç®—å­)...")
        with torch.no_grad():
            for _ in range(15): # å¢åŠ é¢„çƒ­æ¬¡æ•°è®© MIOpen å®Œæˆæœç´¢
                _ = module(*inputs)
        torch.cuda.synchronize()
        
        # 2. æ­£å¼è®¡æ—¶
        start = time.time()
        with torch.no_grad():
            for _ in range(iters):
                _ = module(*inputs)
        torch.cuda.synchronize()
        
        avg_time = (time.time() - start) / iters * 1000 
        throughput = 1000 / avg_time * inputs[0].shape[0] 
        
        print(f"   â±ï¸ å¹³å‡è€—æ—¶: {avg_time:.2f} ms / batch")
        print(f"   ğŸš€ ååé‡: {throughput:.1f} samples/s")
        return avg_time

    except Exception as e:
        print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
        # æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯æ ˆä»¥ä¾¿è°ƒè¯•
        import traceback
        traceback.print_exc()
        return float('inf')

if __name__ == "__main__":
    # æ£€æµ‹ç¡¬ä»¶
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        print(f"\nğŸ”¥ ç¡¬ä»¶å°±ç»ª: {gpu_name}")
        print(f"ğŸ“¦ æ˜¾å­˜æ€»é‡: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
        print("âœ… æ£€æµ‹åˆ° RDNA æ¶æ„ï¼Œå·²å¯ç”¨ MIOPEN ä¼˜åŒ–è¡¥ä¸")
    
    # è®¾å®šå‚æ•°ï¼šåŒ¹é…ä½ çš„ Carbon_SR_Project å®é™…æ•°æ®
    B, T, H, W = 4, 3, 128, 128
    DIM = 64 
    print(f"âš™ï¸ æµ‹è¯•å‚æ•°: BatchSize={B}, Dim={DIM}, PatchSize={H}x{W}")
    print("-" * 50)
    
    # æ„é€ å‡æ•°æ® (è¾“å…¥é€šé“: aux=9, main=1)
    df = torch.randn(B, DIM, T, H, W)
    da = torch.randn(B, DIM, T, H, W) 
    dra = torch.randn(B, 9, T, H, W)
    dm = torch.randn(B, 1, T, H, W)
    
    results = {}

    try:
        # 1. æµ‹è¯•å„æ ¸å¿ƒç»„ä»¶
        results['MultiScaleBlock (3D Conv)'] = benchmark("3Då·ç§¯æ¨¡å—", MultiScaleBlock3D(channels=DIM), df)
        results['MoE Block (Expert)'] = benchmark("MoEä¸“å®¶æ¨¡å—", MoEBlock(dim=DIM, num_experts=3, top_k=1), df)
        
        # âœ… é‡ç‚¹å…³æ³¨ï¼šä½¿ç”¨é€‚é…å™¨æµ‹è¯•å®˜æ–¹ Mamba
        results['Official Mamba (ROCm/C++)'] = benchmark("å®˜æ–¹Mamba(ç¡¬ä»¶åŠ é€Ÿ)", MambaAdapter(dim=DIM), df)

        results['SFT Fusion'] = benchmark("ç‰¹å¾èåˆæ¨¡å—", SFTLayer3D(channels=DIM), (df, da))
        results['Context Attn'] = benchmark("ä¸Šä¸‹æ–‡æ³¨æ„åŠ›", EfficientContextBlock(dim=DIM), df)

        # 2. å®Œæ•´æ¨¡å‹æµ‹è¯•
        # è¿™é‡Œä¼šè°ƒç”¨æˆ‘ä»¬åœ¨ network.py é‡Œæ”¹å¥½çš„ä»£ç 
        full_model = DSTCarbonFormer(aux_c=9, main_c=1, dim=DIM)
        results['>>> FULL MODEL'] = benchmark("DSTCarbonFormerå…¨ç½‘æµ‹è¯•", full_model, (dra, dm))

        # 3. æ€§èƒ½æ’è¡Œæ¦œ
        print("\n" + "="*50)
        print("ğŸ“Š æ¨¡å—é€Ÿåº¦æ’è¡Œæ¦œ (14600K + RX 9060 XT)")
        print("="*50)
        
        valid_res = sorted({k: v for k, v in results.items() if v != float('inf')}.items(), key=lambda x: x[1])
        for name, t in valid_res:
            bar = "â–ˆ" * int(t/5) if t < 200 else "â–ˆ" * 40
            print(f"{name:<30} : {t:>7.2f} ms  {bar}")
            
    except Exception as e:
        print(f"\nâŒ ä¸¥é‡é”™è¯¯: {e}")