import torch
from torch.utils.data import Dataset
import numpy as np
import os
import json

# ==========================================
# âš™ï¸ å…¨å±€å½’ä¸€åŒ–å‚æ•°
# ==========================================
NORM_ROAD = 11.0 
NORM_NTL_LOG = 6.0   
NORM_MAIN_LOG = 11.0

class DualStreamDataset(Dataset):
    def __init__(self, data_dir, split_config_path, mode='train', time_window=3):
        self.data_dir = data_dir
        self.window = time_window
        
        # åŠ è½½ç´¢å¼•é…ç½®
        with open(split_config_path, 'r') as f:
            config = json.load(f)
        
        if mode == 'train':
            self.indices = config['train_indices']
        elif mode == 'val':
            self.indices = config['val_indices']
        else:
            self.indices = config['test_indices']
            
        self.all_years = range(2014, 2024)
        
        # è¾…åŠ©æµå½’ä¸€åŒ–å› å­ (9ä¸ªé€šé“)
        factors = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] 
        self.aux_factors = torch.tensor(factors).float().view(9, 1, 1, 1)

        # æ„å»ºæ ·æœ¬åˆ—è¡¨
        self.samples = []
        for idx in self.indices:
            # æ»‘åŠ¨çª—å£ï¼šä¾‹å¦‚ [2014, 2015, 2016], [2015, 2016, 2017] ...
            for i in range(len(self.all_years) - self.window + 1):
                years = list(self.all_years[i : i+self.window])
                self.samples.append({'patch_idx': idx, 'years': years})
        
        # ==========================================
        # ğŸ”¥ æš´åŠ›æé€Ÿï¼šå…¨é‡é¢„åŠ è½½ (RAM Mode)
        # ==========================================
        print(f"ğŸš€ [{mode}] æ­£åœ¨å°†æ•°æ®åŠ è½½åˆ°å†…å­˜ (è§£å†³ IO ç“¶é¢ˆ)...")
        self.cache_X = {} 
        self.cache_Y = {} 
        
        try:
            for y in self.all_years:
                x_path = os.path.join(self.data_dir, f"X_{y}.npy")
                y_path = os.path.join(self.data_dir, f"Y_{y}.npy")
                
                if os.path.exists(x_path) and os.path.exists(y_path):
                    # ç›´æ¥ load åˆ°å†…å­˜ï¼Œå¤§å¹…æå‡è®­ç»ƒé€Ÿåº¦
                    self.cache_X[y] = np.load(x_path) 
                    self.cache_Y[y] = np.load(y_path)
                else:
                    print(f"âš ï¸ ç¼ºæ•°æ®: {y}")
            print(f"âœ… [{mode}] åŠ è½½å®Œæˆï¼å½“å‰å†…å­˜å ç”¨è¾ƒé«˜ï¼Œä½†é€Ÿåº¦æœ€å¿«ã€‚")
        except MemoryError:
            print(f"âŒ å†…å­˜ä¸è¶³ï¼å¦‚æœä¸å¹¸çˆ†å†…å­˜ï¼Œå»ºè®®åœ¨ __init__ ä¸­æ”¹å› mmap_mode='r'")
            raise

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, index):
        item = self.samples[index]
        p_idx = item['patch_idx']
        years = item['years']
        
        feat_stack = []
        coarse_stack = []
        
        for y in years:
            # 1. è·å–åŸå§‹æ•°æ® (Numpy)
            if y in self.cache_X:
                x_data = self.cache_X[y][p_idx] # Shape: (9, 128, 128)
                y_data = self.cache_Y[y][p_idx] # Shape: (1, 128, 128)
            else:
                # ç¼ºå¤±å¹´ä»½è¡¥é›¶
                x_data = np.zeros((9, 128, 128), dtype=np.float32)
                y_data = np.zeros((1, 128, 128), dtype=np.float32)
            
            # ==========================================
            # ğŸ›¡ï¸ ã€æ•°æ®é˜²æ¯’é¢å…·ã€‘å¼ºåˆ¶æ¸…æ´— NaN å’Œ Inf
            # ==========================================
            # åœ¨è½¬ Tensor ä¹‹å‰å°±æ¸…æ´—ï¼Œæ•ˆç‡æ›´é«˜
            if np.isnan(x_data).any() or np.isinf(x_data).any():
                x_data = np.nan_to_num(x_data, nan=0.0, posinf=0.0, neginf=0.0)
            
            if np.isnan(y_data).any() or np.isinf(y_data).any():
                y_data = np.nan_to_num(y_data, nan=0.0, posinf=0.0, neginf=0.0)
            # ==========================================
            
            feat_stack.append(x_data)
            coarse_stack.append(y_data)
        
        # 2. å †å æ—¶é—´ç»´åº¦ -> Tensor
        # Result Shape: [Channel, Time, H, W]
        feat_tensor = torch.from_numpy(np.stack(feat_stack, axis=1)).float()
        coarse_tensor = torch.from_numpy(np.stack(coarse_stack, axis=1)).float()
        
        # 3. å†æ¬¡å…œåº•æ£€æŸ¥ (é˜²æ­¢ stack è¿‡ç¨‹ä¸­äº§ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè™½ç„¶æ¦‚ç‡æä½)
        feat_tensor = torch.nan_to_num(feat_tensor, nan=0.0)
        coarse_tensor = torch.nan_to_num(coarse_tensor, nan=0.0)
        
        # 4. å½’ä¸€åŒ– (Normalization)
        feat_norm = feat_tensor / self.aux_factors
        # é“è·¯è·¯ç½‘å½’ä¸€åŒ–
        feat_norm[1] = feat_tensor[1] / NORM_ROAD
        # å¤œå…‰é¥æ„Ÿå¯¹æ•°å½’ä¸€åŒ–
        feat_norm[6] = torch.log1p(feat_tensor[6]) / NORM_NTL_LOG
        # ä¸»ç›®æ ‡å¯¹æ•°å½’ä¸€åŒ–
        coarse_norm = torch.log1p(coarse_tensor) / NORM_MAIN_LOG
        
        return feat_norm, coarse_norm, coarse_norm