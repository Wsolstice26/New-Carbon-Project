import torch
from torch.utils.data import Dataset
import torch.nn.functional as F
import numpy as np
import os
import json

# å…¨å±€å½’ä¸€åŒ–å‚æ•°
NORM_ROAD = 11.0 
NORM_NTL_LOG = 6.0   
NORM_MAIN_LOG = 11.0

class DualStreamDataset(Dataset):
    def __init__(self, data_dir, split_config_path, mode='train', time_window=3):
        # å¼ºåˆ¶æŒ‡å‘å®é™…æ•°æ®æ–‡ä»¶å¤¹
        self.data_dir = "/home/wdc/Carbon-Emission-Super-Resolution/data/Train_Data_Yearly_120"
        self.window = time_window
        self.mode = mode
        
        # 1. åŠ è½½ç´¢å¼•é…ç½®
        with open(split_config_path, 'r') as f:
            config = json.load(f)
        
        if mode == 'train':
            self.indices = config['train_indices']
        elif mode == 'val':
            self.indices = config['val_indices']
        else:
            self.indices = config['test_indices']
            
        self.all_years = range(2014, 2024)
        
        # è¾…åŠ©æµå½’ä¸€åŒ–å› å­
        self.aux_factors = torch.tensor([1.0]*9).float().view(9, 1, 1, 1)

        # 2. æ„å»ºæ ·æœ¬ç´¢å¼•åˆ—è¡¨
        self.samples = []
        for idx in self.indices:
            for i in range(len(self.all_years) - self.window + 1):
                years = list(self.all_years[i : i+self.window])
                self.samples.append({'patch_idx': idx, 'years': years})
        
        # 3. é¢„åŠ è½½æ•°æ®åˆ°å†…å­˜ (32GB RAM æ¨¡å¼)
        print(f"ğŸš€ [{mode}] æ­£åœ¨åŠ è½½åˆ‡ç‰‡æ•°æ® (Path: {self.data_dir})...")
        self.cache_X = {} 
        self.cache_Y = {} 
        
        for y in self.all_years:
            x_path = os.path.join(self.data_dir, f"X_{y}.npy")
            y_path = os.path.join(self.data_dir, f"Y_{y}.npy")
            
            if os.path.exists(x_path):
                # ğŸ”¥ [å…³é”®] ä½¿ç”¨ .copy() ç¡®ä¿å†…å­˜ç‹¬ç«‹ä¸”è¿ç»­ï¼Œé˜²æ­¢å¤šçº¿ç¨‹æ®µé”™è¯¯
                self.cache_X[y] = np.load(x_path).copy()
                self.cache_Y[y] = np.load(y_path).copy()
        print(f"âœ… [{mode}] æ•°æ®åŠ è½½å®Œæˆï¼Œæ€»æ ·æœ¬æ•°: {len(self.samples)}")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, index):
        item = self.samples[index]
        p_idx = item['patch_idx']
        years = item['years']
        
        feat_stack = []
        coarse_stack = []
        
        for y in years:
            feat_stack.append(self.cache_X[y][p_idx])
            coarse_stack.append(self.cache_Y[y][p_idx])
        
        # è½¬æ¢ä¸º Tensor [C, T, H, W]
        feat_tensor = torch.from_numpy(np.stack(feat_stack, axis=1)).float()
        target_tensor = torch.from_numpy(np.stack(coarse_stack, axis=1)).float()

        # ============================================================
        # ğŸ¨ã€æ ¸å¿ƒä¿®æ”¹ã€‘å…¨å±€å¹³å‡å…ˆéªŒ (Global Average Prior)
        # ============================================================
        # 1. ç›´æ¥è®¡ç®—æ—¶é—´è½´ä¸Šæ¯ä¸€å¸§çš„å‡å€¼ [1, T, 1, 1]
        # ä½¿ç”¨ keepdim=True æ–¹ä¾¿åç»­å¹¿æ’­ï¼Œæ— éœ€ä½¿ç”¨ expand_as æ‰‹åŠ¨å¤åˆ¶å†…å­˜
        # è¿™ä¸€æ­¥ä»£æ›¿äº†åŸæ¥çš„ AvgPool -> Nearest Interpolateï¼Œå®ç°äº†â€œç™½çº¸â€è¾“å…¥
        global_mean = torch.mean(target_tensor, dim=(2, 3), keepdim=True)
        
        # 2. è‡ªåŠ¨å¹¿æ’­ (Broadcasting) å½¢æˆæ²¡æœ‰ä»»ä½•ä½ç½®ä¿¡æ¯çš„å¹³æ»‘è¾“å…¥
        # æ­¤æ—¶ input_flat çš„æ¯ä¸ªåƒç´ éƒ½ç­‰äºè¯¥å¹´ä»½çš„å‡å€¼
        input_flat = global_mean + torch.zeros_like(target_tensor)

        # 3. å½’ä¸€åŒ–
        feat_norm = feat_tensor / self.aux_factors
        feat_norm[0] = feat_tensor[0] / NORM_ROAD
        # å¢åŠ  clamp(min=0) æå‡ ROCm ç¯å¢ƒä¸‹çš„æ•°å€¼å®‰å…¨æ€§
        feat_norm[6] = torch.log1p(feat_tensor[6].clamp(min=0)) / NORM_NTL_LOG
        
        input_norm = torch.log1p(input_flat.clamp(min=0)) / NORM_MAIN_LOG
        target_norm = torch.log1p(target_tensor.clamp(min=0)) / NORM_MAIN_LOG
        
        return feat_norm, input_norm, target_norm