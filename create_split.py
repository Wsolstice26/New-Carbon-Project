import os
import numpy as np
import json
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import time

# ==========================================
# âš™ï¸ é…ç½®ï¼šä¿®æ”¹ä¸º Linux çœŸå®è·¯å¾„
# ==========================================
# ä½ çš„çœŸå®æ•°æ®å­˜æ”¾ä½ç½®
DATA_DIR = "/home/wdc/Carbon-Emission-Super-Resolution/data/Train_Data_Yearly_Coords" 
# é…ç½®æ–‡ä»¶ç”Ÿæˆçš„ç›®å½•
CONFIG_DIR = "/home/wdc/Carbon-Emission-Super-Resolution/Configs"

def generate_split_config():
    print(f"ğŸš€ å‡†å¤‡å¼€å§‹å¤„ç†...")
    steps = 4
    
    with tqdm(total=steps, desc="æ­£åœ¨åˆå§‹åŒ–", unit="step") as pbar:
        # --- æ­¥éª¤ 1: æ‰«ææ–‡ä»¶ ---
        pbar.set_description("ğŸ“‚ æ­¥éª¤ 1/4: æ‰«ææ–‡ä»¶å¤´ä¿¡æ¯")
        
        # ä½ çš„æ–‡ä»¶å¤¹é‡Œåº”è¯¥æœ‰ç±»ä¼¼ X_2014.npy, X_2015.npy ç­‰æ–‡ä»¶
        # æˆ‘ä»¬ç”¨å…¶ä¸­ä¸€ä¸ªæ¥è¯»å–æ€»æ•°æ®é‡ (total_patches)
        # å¦‚æœä½ çš„æ–‡ä»¶åä¸åŒï¼Œè¯·æ£€æŸ¥ DATA_DIR ä¸‹çš„æ–‡ä»¶
        ref_file = os.path.join(DATA_DIR, "X_2014.npy")
        
        if not os.path.exists(ref_file):
            print(f"\nâŒ é”™è¯¯ï¼šåœ¨ {DATA_DIR} ä¸­æ‰¾ä¸åˆ° X_2014.npyã€‚")
            print("è¯·ç¡®è®¤ä½ çš„ .npy æ–‡ä»¶åæ˜¯å¦æ­£ç¡® (ä¾‹å¦‚æ˜¯å¦å« X_2014.npy æˆ–å…¶ä»–å¹´ä»½)ã€‚")
            # å°è¯•è‡ªåŠ¨å¯»æ‰¾ä¸€ä¸ª .npy æ–‡ä»¶ä½œä¸ºæ›¿ä»£
            npy_files = [f for f in os.listdir(DATA_DIR) if f.startswith("X_") and f.endswith(".npy")]
            if npy_files:
                ref_file = os.path.join(DATA_DIR, npy_files[0])
                print(f"ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°: {npy_files[0]}")
            else:
                return
            
        try:
            # mmap_mode='r' å…è®¸è¯»å–å¤§æ–‡ä»¶è€Œä¸åŠ è½½è¿›å†…å­˜
            data = np.load(ref_file, mmap_mode='r')
            total_patches = data.shape[0]
            print(f"   ğŸ“Š æ£€æµ‹åˆ°æ¯ä¸ªæ–‡ä»¶åŒ…å« {total_patches} ä¸ªæ ·æœ¬")
        except Exception as e:
            print(f"\nâŒ è¯»å–æ–‡ä»¶å‡ºé”™: {e}")
            return
            
        pbar.update(1)

        # --- æ­¥éª¤ 2: ç”Ÿæˆç´¢å¼• ---
        pbar.set_description(f"ğŸ”¢ æ­¥éª¤ 2/4: ç”Ÿæˆç´¢å¼• (å…± {total_patches} ä¸ª)")
        all_indices = np.arange(total_patches)
        pbar.update(1)

        # --- æ­¥éª¤ 3: éšæœºåˆ’åˆ† ---
        pbar.set_description("âœ‚ï¸ æ­¥éª¤ 3/4: æ­£åœ¨è¿›è¡Œéšæœºåˆ’åˆ† (8:1:1)")
        train_idx, temp_idx = train_test_split(
            all_indices, train_size=0.8, random_state=2026, shuffle=True
        )
        val_idx, test_idx = train_test_split(
            temp_idx, test_size=0.5, random_state=2026, shuffle=True
        )
        pbar.update(1)

        # --- æ­¥éª¤ 4: ä¿å­˜ç»“æœ ---
        pbar.set_description("ğŸ’¾ æ­¥éª¤ 4/4: æ­£åœ¨å†™å…¥é…ç½®æ–‡ä»¶")
        
        config_data = {
            "total_patches": int(total_patches),
            "train_indices": train_idx.tolist(),
            "val_indices": val_idx.tolist(),
            "test_indices": test_idx.tolist()
        }

        if not os.path.exists(CONFIG_DIR):
            os.makedirs(CONFIG_DIR, exist_ok=True)
            
        out_path = os.path.join(CONFIG_DIR, "split_config.json")
        
        with open(out_path, 'w') as f:
            json.dump(config_data, f)
            
        pbar.update(1)

    print(f"\nâœ… å¤„ç†å®Œæˆï¼é…ç½®æ–‡ä»¶å·²ä¿å­˜è‡³: {out_path}")
    print(f"ğŸ‘‰ ç°åœ¨çš„è®­ç»ƒé›†æ•°é‡: {len(train_idx)}, éªŒè¯é›†: {len(val_idx)}, æµ‹è¯•é›†: {len(test_idx)}")

if __name__ == "__main__":
    generate_split_config()